{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Python Project - A  Classification Project\n",
    "\n",
    "This project counts as your final exam in Python.  \n",
    "\n",
    "In this project we want to predict the quality of a white wine based NOT on its region, grape or production year but rather on some chemical characteristics.  The sweetness of a wine comes from  sugar whereas the tartness comes from acidic components.  White wines have much lower levels of tannins than red wine so this is not included as a feature here.\n",
    "\n",
    "Suppose you have a good wine palette and only want to select wines which have a quality rating of  7 or higher on a scale of 1 to 10.  So we want to turn this into a binary classification problem where we predict whether the wine is acceptable (1=True) or not acceptable (0=False) to purchase.  The given data set provides several chemical features (see  description below) and a quality rating between 1 and 10. \n",
    "\n",
    "Once we have cleaned the data, separated it into training and test sets and then scaled it, we compare the 3 classification algorithms Logistic Regression, ANN and kNN for predicting whether a wine is acceptable or not based upon our criteria of a rating of 7 or higher. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Before fitting the data we need to put it in a data frame with the desired target value (0 or 1) and then we need to clean the data.  To do this we complete the following steps.\n",
    "\n",
    "1. We first determine if there are any data instances which have a feature value of NaN.  If there are, delete these instances unless there are too many.  If the majority of NaN's occur within a single feature, drop that feature.\n",
    "2. Data instances which are _outliers_ may skew the outcome of our algorithms so we want to delete such data, if possible. By an outlier we mean a data instance which has a feature value that is far from the mean. For example, for the residual sugar feature the mean is around 6.4 with a standard deviation of around 5.  However, the maximum value occurring for residual    is almost 66 so we may consider this data instance an outlier; note that its distance from the mean (|6.4-66|=61.6) is around 12 times its standard deviation so clearly something is wrong.  The criteria we use to identify data entries as outliers is somewhat arbitrary but typically one requires the difference of the feature value from the feature mean to be less than some multiple of the standard deviation. In our case we will assume that points which are more than 5 standard deviations from the mean are outliers.  So our criteria for determining if a data instance with feature value x is an outlier is\n",
    "       | x - mean |  > 5 times the standard deviation \n",
    "where mean and standard deviation are for the feature.\n",
    "However, we do not want to delete too much data.  If a feature has a large number of outliers then it is probably better to just not use that feature.  In our data set we won't have to delete too many data instances so don't worry about deleting a feature.  It is important to realize that in some applications, such as climate, outliers may be important and should not be deleted.\n",
    "\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset - White wine quality\n",
    "\n",
    "This is a dataset which is used to predict the quality of a white wine based upon several features.  The data is in the file 'white_wine_quality.csv'.  However the data is NOT separated by a comma but rather by a semi-colon.  This can be handled by the usual pandas command for reading a csv file except that you need to add the argument __sep=';'__\n",
    "\n",
    "The features are:\n",
    "1. fixed acidity (tartaric acid - g / dm^3): most acids involved with wine are fixed or nonvolatile (do not evaporate readily)\n",
    "\n",
    "1. volatile acidity (acetic acid - g / dm^3): the amount of acetic acid in wine, which at too high of levels can lead to an unpleasant, vinegar taste\n",
    "\n",
    "1. citric acid (g / dm^3): found in small quantities, citric acid can add ‘freshness’ and flavor to wines\n",
    "\n",
    "1. residual sugar (g / dm^3): the amount of sugar remaining after fermentation stops, it’s rare to find wines with less than 1 gram/liter and wines with greater than 45 grams/liter are considered sweet\n",
    "\n",
    "1. chlorides (sodium chloride - g / dm^3): the amount of salt in the wine\n",
    "\n",
    "1. free sulfur dioxide (mg / dm^3):   prevents microbial growth and the oxidation of wine\n",
    "\n",
    "1. total sulfur dioxide (mg / dm^3):   in low concentrations, SO2 is mostly undetectable in wine, but at free SO2 concentrations over 50 ppm, SO2 becomes evident in the nose and taste of wine\n",
    "\n",
    "1. density (g / cm^3): the density of wine is close to that of water depending on the percent alcohol and sugar content\n",
    "\n",
    "1. pH: describes how acidic or basic a wine is on a scale from 0 (very acidic) to 14 (very basic); most wines are between 3-4 on the pH scale\n",
    "\n",
    "1. sulphates (potassium sulphate - g / dm3): a wine additive which can contribute to sulfur dioxide gas (S02) levels, wich acts as an antimicrobial and antioxidant\n",
    "\n",
    "1. alcohol (% by volume): the percent alcohol content of the wine\n",
    "\n",
    "\n",
    "The target/outcome in the data file is a number between 0 and 10 indicating the perceived __quality__ of the wine.  This data set may not contain wines from each quality rating.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What to do --\n",
    "\n",
    "__Step 0__ Import libraries \n",
    "\n",
    "__Step 1__ Load data and  create a dataframe. Add a column to the data frame which gives the target value of 1 if the quality rating is 7 or higher and 0 otherwise; this answers the question \"Is the wine acceptable?\" based on our given criteria.  Print out enough lines in your data frame to show that this column is correct.  Hint:  To create the extra column you can use the __.map()__ method as we did many times with the iris data set or __.apply()__ as we did in the diabetes dataset in Week 13\n",
    " \n",
    "__Step 2__ Determine how many data instances are in the file; add a formatted print statement giving this value. Check to make sure there are no values containing NaN; if there are, delete those data entries.\n",
    "\n",
    "__Step 3__ Decide how many different quality classes (based on the quality rating of 1 to 10) this data is divided into and how many wines are in each class. What quality rating does the  majority of the wines in the dataset have?  Give a frequency  plot (using, for example, Seaborn's   __countplot__) for each quality class and give the actual numbers in each quality rating. (The __groupby__ method for a dataframe may be useful.)\n",
    "\n",
    "__Step 4__   We now want to delete each data entry which has an outlier for any feature based upon the criteria we gave (i.e., the difference of a feature value from the feature mean is > five times the standard deviation).  For each feature starting with 'fixed acidity' and going in feature order, loop through the data entries and see if the value is an outlier; if it is, delete that data entry.  For each feature print out how many data instances you deleted.  Remember that NumPy has built-in functions to determine the mean   and standard deviation (__np.std(f)__); here __f__ is a NumPy array containing feature information.  How many data instances are remaining in the data frame after the data entries containing outliers are eliminated?\n",
    "\n",
    "__Step 5__  Put the data into the correct form for the classifiers.  Remember that the target array y is just 0 or 1 (acceptable or not).  To get the feature data you can either use ```vstack``` for all 11 features or an easier way is to create a new data frame where you drop the columns that do not contain the feature data and then create a 2D NumPy array from this using, for example, ```X = df_mod.values``` where ```df_mod``` is your modified dataframe. Either way, X should be dimensioned by the number of data entries at the end of Step 4 by 11 features.\n",
    "\n",
    "__Step 6__  Split the data into training and test sets with an 80-20 split using scikit-learn's function ```train_test_learn```.  Print out the number of data instances in each set.\n",
    "\n",
    "__Step 7__  Scale the data as we have done previously using scikit-learn's ```StandardScaler```\n",
    "\n",
    "__Step 8__ Apply scikit-learn's logistic regression algorithm to solve this binary classification problem. Be sure to set the solver using ```lbfgs```. Print out the percent of accuracy for predicting the test set. \n",
    "\n",
    "__Step 9__ Apply scikit-learn's ANN algorithm to solve this binary classification problem.  Print out the percent of accuracy for predicting the test set. \n",
    "\n",
    "__Step 10__ Apply scikit-learn's kNN algorithm to solve this binary classification problem for values of k=1 to k=5.  Determine which choice of k gives the best result.  Print out the percent of accuracy for predicting the test set. \n",
    "\n",
    "__Step 11__ Compare results from the 3 algorithms.\n",
    "\n",
    "___Extra Credit___ Apply 1 or more additional algorithms from scikit-learn's library to this binary classification problem and compare with the 3 algorithms in steps 8-10.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - create dataframe\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 continued.  Is the wine acceptable? 1 = True, 0 = False\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2. Nan values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3. Quality groupings and countplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4. For each feature determine if any data instance is an outlier; \n",
    "# if it is delete that data instance\n",
    " # Example follows for one feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.21758267510449\n",
      "5.67196082288019\n",
      "6.267184661670337\n",
      "7.209622406421397\n",
      "6.4655926079337185\n",
      "5.3247469169192705\n",
      "6.812806513894635\n",
      "8.152060151172464\n",
      "5.0271349975241995\n",
      "number of data instances dropped is  9\n"
     ]
    }
   ],
   "source": [
    "#  Step 4 example - volatile acidity feature \n",
    "f = df['volatile acidity'].values\n",
    " \n",
    "mean = np.mean(f)\n",
    "std = np.std(f)\n",
    "n = len(f)\n",
    "count = 0\n",
    "for i in range (0,n):\n",
    "    z = ( f[i] - mean ) / std\n",
    "    if (z>factor) :\n",
    "        print (z)\n",
    "        count = count + 1\n",
    "        df = df.drop( [i])\n",
    "print (\"number of data instances dropped is \", count) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5. get data into correct form\n",
    "#\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6. Split data in test and trial sets with 80-20 split\n",
    "from sklearn.model_selection import train_test_split\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7. Scale the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Step 8. Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9. Create ANN classifier and train \n",
    "\n",
    "from sklearn.neural_network import MLPClassifier   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10. Create kNN classifier and see what value of k is best\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
